{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Monitor Review Notebook\n",
    "\n",
    "## Purpose\n",
    "This notebook is used for **post-hoc strategy review** of cloud monitoring data.\n",
    "\n",
    "### Analysis Areas:\n",
    "1. **Market Regime Analysis**: Which regimes cause IC drops / gate tightening\n",
    "2. **Feature Stability**: Which features are unstable in certain time periods\n",
    "3. **Alert Patterns**: When and why alerts occur\n",
    "4. **Feedback Loop**: Insights for feature engineering, gate design, position sizing\n",
    "\n",
    "### Data Sources:\n",
    "- `warehouse/monitoring/hourly_runlog.jsonl` (local or pulled from EC2)\n",
    "- `cloud_logs/YYYY-MM-DD/` (daily backups from EC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Cloud Monitor Review Notebook loaded\")\n",
    "print(f\"Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Runlog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_runlog(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load hourly_runlog.jsonl into a DataFrame\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                try:\n",
    "                    records.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    if 'ts_run' in df.columns:\n",
    "        df['ts_run'] = pd.to_datetime(df['ts_run'])\n",
    "        df = df.sort_values('ts_run').reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_multiple_runlogs(base_dir: str, date_range: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load runlogs from multiple date directories in cloud_logs/\n",
    "    \"\"\"\n",
    "    base = Path(base_dir)\n",
    "    all_records = []\n",
    "    \n",
    "    for date_dir in sorted(base.iterdir()):\n",
    "        if not date_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        if date_range:\n",
    "            dir_date = date_dir.name\n",
    "            if dir_date < date_range[0] or dir_date > date_range[1]:\n",
    "                continue\n",
    "        \n",
    "        runlog_path = date_dir / 'hourly_runlog.jsonl'\n",
    "        if runlog_path.exists():\n",
    "            df_day = load_runlog(str(runlog_path))\n",
    "            all_records.append(df_day)\n",
    "            print(f\"  Loaded {len(df_day)} records from {date_dir.name}\")\n",
    "    \n",
    "    if all_records:\n",
    "        return pd.concat(all_records, ignore_index=True)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load from local warehouse (if running on EC2 or synced)\n",
    "LOCAL_RUNLOG = Path('warehouse/monitoring/hourly_runlog.jsonl')\n",
    "\n",
    "# Option 2: Load from cloud_logs backup directory\n",
    "CLOUD_LOGS_DIR = Path('cloud_logs')\n",
    "\n",
    "# Choose data source\n",
    "if LOCAL_RUNLOG.exists():\n",
    "    print(\"Loading from local runlog...\")\n",
    "    df_runlog = load_runlog(str(LOCAL_RUNLOG))\n",
    "elif CLOUD_LOGS_DIR.exists():\n",
    "    print(\"Loading from cloud_logs directory...\")\n",
    "    df_runlog = load_multiple_runlogs(str(CLOUD_LOGS_DIR))\n",
    "else:\n",
    "    print(\"No runlog data found. Run the EC2 monitoring first or pull logs.\")\n",
    "    df_runlog = pd.DataFrame()\n",
    "\n",
    "if len(df_runlog) > 0:\n",
    "    print(f\"\\nTotal records loaded: {len(df_runlog)}\")\n",
    "    print(f\"Date range: {df_runlog['ts_run'].min()} to {df_runlog['ts_run'].max()}\")\n",
    "    print(f\"\\nColumns: {list(df_runlog.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview\n",
    "if len(df_runlog) > 0:\n",
    "    display(df_runlog.head())\n",
    "    display(df_runlog.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Execution Success Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_runlog) > 0 and 'status' in df_runlog.columns:\n",
    "    # Daily success rate\n",
    "    df_runlog['date'] = df_runlog['ts_run'].dt.date\n",
    "    \n",
    "    daily_stats = df_runlog.groupby('date').agg({\n",
    "        'status': ['count', lambda x: (x == 'SUCCESS').sum()]\n",
    "    }).reset_index()\n",
    "    daily_stats.columns = ['date', 'total', 'success']\n",
    "    daily_stats['success_rate'] = daily_stats['success'] / daily_stats['total']\n",
    "    \n",
    "    print(\"Daily Execution Summary:\")\n",
    "    display(daily_stats)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.bar(range(len(daily_stats)), daily_stats['success_rate'], color='steelblue')\n",
    "    ax.set_xticks(range(len(daily_stats)))\n",
    "    ax.set_xticklabels([str(d) for d in daily_stats['date']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('Success Rate')\n",
    "    ax.set_title('Daily Execution Success Rate')\n",
    "    ax.axhline(y=0.95, color='green', linestyle='--', label='95% target')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. IC/IR/PMR Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_runlog) > 0 and 'ic_15d' in df_runlog.columns:\n",
    "    # Filter successful runs with metrics\n",
    "    df_metrics = df_runlog[df_runlog['status'] == 'SUCCESS'].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    # IC 15d\n",
    "    axes[0].plot(df_metrics['ts_run'], df_metrics['ic_15d'], 'b-', alpha=0.7, label='IC 15d')\n",
    "    axes[0].axhline(y=0.02, color='red', linestyle='--', label='Hard Gate (0.02)')\n",
    "    axes[0].fill_between(df_metrics['ts_run'], 0.02, df_metrics['ic_15d'].min(), \n",
    "                         where=df_metrics['ic_15d'] < 0.02, alpha=0.3, color='red')\n",
    "    axes[0].set_ylabel('IC (15d Rolling)')\n",
    "    axes[0].legend(loc='upper right')\n",
    "    axes[0].set_title('Rolling IC Performance')\n",
    "    \n",
    "    # IR 15d\n",
    "    axes[1].plot(df_metrics['ts_run'], df_metrics['ir_15d'], 'g-', alpha=0.7, label='IR 15d')\n",
    "    axes[1].axhline(y=0.5, color='red', linestyle='--', label='Hard Gate (0.5)')\n",
    "    axes[1].set_ylabel('IR (15d Rolling)')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    \n",
    "    # PMR 15d\n",
    "    axes[2].plot(df_metrics['ts_run'], df_metrics['pmr_15d'], 'purple', alpha=0.7, label='PMR 15d')\n",
    "    axes[2].axhline(y=0.55, color='red', linestyle='--', label='Hard Gate (0.55)')\n",
    "    axes[2].set_ylabel('PMR (15d Rolling)')\n",
    "    axes[2].set_xlabel('Time')\n",
    "    axes[2].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nMetric Summary (15-day rolling):\")\n",
    "    print(df_metrics[['ic_15d', 'ir_15d', 'pmr_15d']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Position Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_runlog) > 0 and 'position' in df_runlog.columns:\n",
    "    df_pos = df_runlog[df_runlog['status'] == 'SUCCESS'].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Position time series\n",
    "    axes[0].plot(df_pos['ts_run'], df_pos['position'] * 100, 'b-', alpha=0.7)\n",
    "    axes[0].axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "    axes[0].axhline(y=15, color='orange', linestyle='--', label='Initial Weight (15%)')\n",
    "    axes[0].axhline(y=-15, color='orange', linestyle='--')\n",
    "    axes[0].axhline(y=30, color='red', linestyle='--', label='Max Weight (30%)')\n",
    "    axes[0].axhline(y=-30, color='red', linestyle='--')\n",
    "    axes[0].set_ylabel('Position (%)')\n",
    "    axes[0].set_xlabel('Time')\n",
    "    axes[0].set_title('Position Over Time')\n",
    "    axes[0].legend(loc='upper right')\n",
    "    \n",
    "    # Position histogram\n",
    "    axes[1].hist(df_pos['position'] * 100, bins=30, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "    axes[1].axvline(x=0, color='gray', linestyle='-', alpha=0.5)\n",
    "    axes[1].set_xlabel('Position (%)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Position Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Extreme positions\n",
    "    print(\"\\nExtreme Positions:\")\n",
    "    print(f\"  Max Long:  {df_pos['position'].max() * 100:.2f}%\")\n",
    "    print(f\"  Max Short: {df_pos['position'].min() * 100:.2f}%\")\n",
    "    print(f\"  Mean:      {df_pos['position'].mean() * 100:.2f}%\")\n",
    "    print(f\"  Std:       {df_pos['position'].std() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alert Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_runlog) > 0 and 'alerts' in df_runlog.columns:\n",
    "    # Flatten alerts\n",
    "    all_alerts = []\n",
    "    for idx, row in df_runlog.iterrows():\n",
    "        alerts = row.get('alerts', [])\n",
    "        if isinstance(alerts, list):\n",
    "            for alert in alerts:\n",
    "                alert_record = {\n",
    "                    'ts_run': row['ts_run'],\n",
    "                    'level': alert.get('level'),\n",
    "                    'gate': alert.get('gate'),\n",
    "                    'metric': alert.get('metric'),\n",
    "                    'value': alert.get('value'),\n",
    "                    'threshold': alert.get('threshold'),\n",
    "                    'message': alert.get('message')\n",
    "                }\n",
    "                all_alerts.append(alert_record)\n",
    "    \n",
    "    if all_alerts:\n",
    "        df_alerts = pd.DataFrame(all_alerts)\n",
    "        \n",
    "        print(f\"Total alerts: {len(df_alerts)}\")\n",
    "        print(\"\\nAlerts by Level:\")\n",
    "        print(df_alerts['level'].value_counts())\n",
    "        print(\"\\nAlerts by Gate:\")\n",
    "        print(df_alerts['gate'].value_counts())\n",
    "        \n",
    "        # Plot alert timeline\n",
    "        if len(df_alerts) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(14, 4))\n",
    "            \n",
    "            level_colors = {'CRITICAL': 'red', 'WARNING': 'orange', 'INFO': 'blue'}\n",
    "            for level in df_alerts['level'].unique():\n",
    "                mask = df_alerts['level'] == level\n",
    "                ax.scatter(df_alerts.loc[mask, 'ts_run'], \n",
    "                          [level] * mask.sum(),\n",
    "                          c=level_colors.get(level, 'gray'),\n",
    "                          s=100, alpha=0.7, label=level)\n",
    "            \n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Alert Level')\n",
    "            ax.set_title('Alert Timeline')\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No alerts found in the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hard Gate Status Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_runlog) > 0 and 'hard_gate_status' in df_runlog.columns:\n",
    "    print(\"Hard Gate Status Distribution:\")\n",
    "    print(df_runlog['hard_gate_status'].value_counts())\n",
    "    \n",
    "    # Time when status changed\n",
    "    df_runlog['status_change'] = df_runlog['hard_gate_status'] != df_runlog['hard_gate_status'].shift(1)\n",
    "    status_changes = df_runlog[df_runlog['status_change']]\n",
    "    \n",
    "    if len(status_changes) > 1:\n",
    "        print(\"\\nStatus Change Events:\")\n",
    "        display(status_changes[['ts_run', 'hard_gate_status', 'ic_15d', 'ir_15d', 'pmr_15d']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Stability Analysis\n",
    "\n",
    "This section requires joining with feature data to analyze which features correlate with IC drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features data if available\n",
    "FEATURES_PATH = Path('features_hourly_with_term.parquet')\n",
    "\n",
    "if FEATURES_PATH.exists() and len(df_runlog) > 0:\n",
    "    df_features = pd.read_parquet(FEATURES_PATH)\n",
    "    print(f\"Features loaded: {len(df_features)} rows, {len(df_features.columns)} columns\")\n",
    "    \n",
    "    # Feature columns used in the model\n",
    "    model_features = [\n",
    "        'OIL_CORE_norm_art_cnt', 'GEOPOL_norm_art_cnt',\n",
    "        'USD_RATE_norm_art_cnt', 'SUPPLY_CHAIN_norm_art_cnt',\n",
    "        'MACRO_norm_art_cnt', 'cl1_cl2', 'ovx'\n",
    "    ]\n",
    "    \n",
    "    available_features = [f for f in model_features if f in df_features.columns]\n",
    "    print(f\"\\nAvailable model features: {available_features}\")\n",
    "    \n",
    "    if available_features:\n",
    "        # Rolling std of features (stability measure)\n",
    "        stability_df = df_features[available_features].rolling(24).std()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        for col in available_features:\n",
    "            ax.plot(stability_df.index, stability_df[col], alpha=0.7, label=col)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Rolling 24h Std')\n",
    "        ax.set_title('Feature Stability (Lower = More Stable)')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Features data not available for stability analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. System Health Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_runlog) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"SYSTEM HEALTH SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Execution health\n",
    "    total_runs = len(df_runlog)\n",
    "    success_runs = (df_runlog['status'] == 'SUCCESS').sum()\n",
    "    success_rate = success_runs / total_runs if total_runs > 0 else 0\n",
    "    \n",
    "    print(f\"\\n[Execution]\")\n",
    "    print(f\"  Total Runs:    {total_runs}\")\n",
    "    print(f\"  Success Rate:  {success_rate:.1%}\")\n",
    "    \n",
    "    # IC health\n",
    "    if 'ic_15d' in df_runlog.columns:\n",
    "        recent_ic = df_runlog['ic_15d'].dropna().tail(24)\n",
    "        ic_below_gate = (recent_ic < 0.02).sum()\n",
    "        print(f\"\\n[IC Performance - Last 24 observations]\")\n",
    "        print(f\"  Mean IC:       {recent_ic.mean():.4f}\")\n",
    "        print(f\"  Below Gate:    {ic_below_gate} times\")\n",
    "    \n",
    "    # Alert health\n",
    "    if 'hard_gate_status' in df_runlog.columns:\n",
    "        recent_status = df_runlog['hard_gate_status'].tail(24)\n",
    "        healthy_pct = (recent_status == 'HEALTHY').sum() / len(recent_status) if len(recent_status) > 0 else 0\n",
    "        print(f\"\\n[Hard Gate Status - Last 24 observations]\")\n",
    "        print(f\"  Healthy Rate:  {healthy_pct:.1%}\")\n",
    "    \n",
    "    # Host diversity\n",
    "    if 'source_host' in df_runlog.columns:\n",
    "        hosts = df_runlog['source_host'].unique()\n",
    "        print(f\"\\n[Infrastructure]\")\n",
    "        print(f\"  Source Hosts:  {list(hosts)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Actionable Insights\n",
    "\n",
    "Based on the analysis above, document insights for:\n",
    "\n",
    "### Feature Engineering\n",
    "- Which features show high instability?\n",
    "- Are there time periods where specific features fail?\n",
    "\n",
    "### Gate Threshold Design\n",
    "- Are current thresholds too tight/loose?\n",
    "- Should we add market-regime-specific gates?\n",
    "\n",
    "### Position Sizing Logic\n",
    "- Is the position scaling appropriate?\n",
    "- Should we reduce sizing during high-volatility periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual notes section\n",
    "insights = \"\"\"\n",
    "## Review Notes\n",
    "\n",
    "### Date: [FILL IN]\n",
    "\n",
    "### Observations:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "### Recommended Actions:\n",
    "- [ ] \n",
    "- [ ] \n",
    "- [ ] \n",
    "\n",
    "### Follow-up Questions:\n",
    "- \n",
    "\"\"\"\n",
    "\n",
    "print(insights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
